{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOrgAna workflow for advance python users\n",
    "This workflow is intended for users with programming background to analyse multiple image folders at once. Users can also use this notebook to select and adapt modules/functions specific to their purpose. This workflow follows the order of scripts in python_example_scripts and explains the code shown in the scripts in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Masks\n",
    "This section makes use of the code from the following scripts:\n",
    "* '01_create_model_folder.py'\n",
    "* '02_create_ground_truth.py'\n",
    "* '03_train_networks.py'\n",
    "* '04_predict_masks.py'\n",
    "* '05_select_final_mask_method.py'\n",
    "\n",
    "### 01_create_model_folder.py\n",
    "The following code chooses images from the acquired dataset to form the training dataset for the generation of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "# parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condB')\n",
    "parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select images for training dataset\n",
    "start = 0 # increase value to exclude starting images in dataset\n",
    "dN = 0 # every dNth image will be used for the training dataset; if dN = 0, random images are taken\n",
    "\n",
    "# True: create one model for all folders; False: create one model for each image subfolder\n",
    "combine_subfolders = True\n",
    "   \n",
    "# add folders that you want to ignore here\n",
    "exclude_folder = ['model_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_folder(folder, dN=30, start=0, combine=True):\n",
    "    \n",
    "    # create folders\n",
    "    if combine:\n",
    "        model_folder = os.path.join(os.path.split(folder)[0],'model_')\n",
    "    else:\n",
    "        model_folder = os.path.join(os.path.split(folder)[0], 'model_' + os.path.split(folder)[1])\n",
    "\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.mkdir(model_folder)\n",
    "        \n",
    "    trainingset_folder = os.path.join(model_folder,'trainingset')\n",
    "    if not os.path.exists(trainingset_folder):\n",
    "        os.mkdir(trainingset_folder)\n",
    "\n",
    "    # count images and extract trainingset file names\n",
    "    flist = glob.glob(os.path.join(folder,'*.tif'))\n",
    "    flist.sort()\n",
    "    if dN:\n",
    "        flist = flist[start::dN]\n",
    "    else: \n",
    "        rng = default_rng()\n",
    "        random_choice = rng.choice(len(flist), size=np.clip(len(flist)//10, 1, None), replace=False)\n",
    "        flist = [flist[i] for i in random_choice]\n",
    "\n",
    "    \n",
    "    # copy images to trainingset folder\n",
    "    for f in flist:\n",
    "        fname = os.path.split(folder)[1] + '_' + os.path.split(f)[-1]\n",
    "        newf = os.path.join(trainingset_folder,fname)\n",
    "        if not os.path.exists(newf):\n",
    "            shutil.copy(f,newf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute parent folder as absolute path\n",
    "parent_folder = os.path.abspath(parent_folder)\n",
    "    \n",
    "# find out all image subfolders in parent_folder\n",
    "folder_names = next(os.walk(parent_folder))[1] \n",
    "    \n",
    "# exclude folders in exclude_folder\n",
    "folder_names = [g for g in folder_names if not g in exclude_folder ]\n",
    "\n",
    "for folder_name in tqdm(folder_names):\n",
    "    if not folder_name in exclude_folder:\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # for the parent_folder/every image subfolder, generate model folder and the trainingset\n",
    "        initialize_model_folder(folder_path, dN=dN, start=start, combine=combine_subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02_create_ground_truth.py\n",
    "This script creates binary masks (ground truths) for images copied into the trainingset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell if starting from 02_create_ground_truth.py\n",
    "import os, glob\n",
    "from tqdm.notebook import tqdm\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "# parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condA')\n",
    "parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morgana.GUIs.manualmask import makeManualMask\n",
    "from morgana.DatasetTools import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5.QtWidgets\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GT_mask(model_folder, app):\n",
    "    \n",
    "    ### check that model and trainingset exist\n",
    "    if not os.path.exists(model_folder):\n",
    "        print('Warning!')\n",
    "        print(model_folder,':')\n",
    "        print('Model folder not created! Skipping this subfolder.')\n",
    "        return\n",
    "        \n",
    "    trainingset_folder = os.path.join(model_folder,'trainingset')\n",
    "    if not os.path.exists(trainingset_folder):\n",
    "        print('Warning!')\n",
    "        print(model_folder,':')\n",
    "        print('Trainingset images not found! Skipping this subfolder.')\n",
    "        return\n",
    "\n",
    "    ### load trainingset images and previously generated ground truth    \n",
    "    flist_in = io.get_image_list(trainingset_folder, string_filter='_GT', mode_filter='exclude')\n",
    "    flist_in.sort()\n",
    "    flist_gt = io.get_image_list(trainingset_folder, string_filter='_GT', mode_filter='include')\n",
    "    flist_gt.sort()\n",
    "\n",
    "    ### if no trainingset images in the folder, skip this gastruloid\n",
    "    if len(flist_in) == 0:\n",
    "        print('\\n\\nWarning, no trainingset!','Selected \"'+model_folder+'\" but no trainingset *data* detected. Transfer some images in the \"trainingset\" folder.')\n",
    "        return\n",
    "    \n",
    "    ### if there are more trainingset than ground truth, promptuse to make mask\n",
    "    if len(flist_in)!=len(flist_gt):\n",
    "        print('\\n\\nWarning, trainingset incomplete!','Selected \"'+model_folder+'\" but not all masks have been created.\\nPlease provide manually annotated masks.')\n",
    "\n",
    "        for f in flist_in:\n",
    "            fn,ext = os.path.splitext(f)\n",
    "            mask_name = fn+'_GT'+ext\n",
    "\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(mask_name):\n",
    "                if not PyQt5.QtWidgets.QApplication.instance():\n",
    "                    app = PyQt5.QtWidgets.QApplication(sys.argv)\n",
    "                else:\n",
    "                    app = PyQt5.QtWidgets.QApplication.instance() \n",
    "                m = makeManualMask(f,subfolder='',fn=fn+'_GT'+ext,wsize = (2000,2000))\n",
    "                m.show()\n",
    "                app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "\n",
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]\n",
    "\n",
    "app = PyQt5.QtWidgets.QApplication(sys.argv)\n",
    "\n",
    "for model_folder in tqdm(model_folders):\n",
    "    create_GT_mask(model_folder, app)\n",
    "\n",
    "app.quit()\n",
    "print('All binary masks/ground truth images found. Move to the next step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03_train_networks.py\n",
    "This trains the model for further image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image subfolders found in: Y:\\Jia_Le_Lim\\morgana_example_datasets\\gastruloids\\condA\n",
      "Path exists! Proceed!\n"
     ]
    }
   ],
   "source": [
    "# Run cell if starting from 03_train_networks.py\n",
    "import os, glob\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions'\n",
    "# parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condA')\n",
    "parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists\n",
    "\n",
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]\n",
    "\n",
    "model_folders = [os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','brain_organoids','adjusted_input','model_LR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import time\n",
    "from morgana.DatasetTools import io as ioDT\n",
    "from morgana.MLModel import io as ioML\n",
    "from morgana.MLModel import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define parameters for feature generation for network training\n",
    "sigmas = [1.0, 5.0, 15.0]\n",
    "downscaling = 0.25\n",
    "edge_size = 5\n",
    "pxl_extract_fraction = 0.25\n",
    "pxl_extract_bias = 0.4\n",
    "feature_type = 'ilastik' # or 'ilastik'\n",
    "deep = False # True: deep learning with Multi Layer Perceptrons; False: Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 179.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Y:\\Jia_Le_Lim\\morgana_example_datasets\\brain_organoids\\adjusted_input\\model_LR------------\n",
      "##### Training set:\n",
      "1 \t tp01.tif \t tp01_GT.tif\n",
      "2 \t tp09.tif \t tp09_GT.tif\n",
      "3 \t tp11.tif \t tp11_GT.tif\n",
      "4 \t tp17.tif \t tp17_GT.tif\n",
      "5 \t tp22.tif \t tp22_GT.tif\n",
      "##### Generating training set...\n",
      "Number of images: 5\n",
      "Number of pixels extracted per image (25%): [1411, 1411, 1552, 1368, 1552]\n",
      "Number of features per image: 13\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    print('-------------'+model_folder+'------------')\n",
    "\n",
    "    training_folder = os.path.join(model_folder, 'trainingset')\n",
    "\n",
    "    ### load images\n",
    "    flist_in = ioDT.get_image_list(\n",
    "                                              training_folder, \n",
    "                                              string_filter='_GT', \n",
    "                                              mode_filter='exclude'\n",
    "                                              )\n",
    "    img_train = []\n",
    "    for f in flist_in:\n",
    "        img = imread(f)\n",
    "        if len(img.shape)==2:\n",
    "            img = np.expand_dims(img,0)\n",
    "        if img.shape[-1] == np.min(img.shape):\n",
    "            img = np.moveaxis(img, -1, 0)\n",
    "        img_train.append( img[0] )\n",
    "\n",
    "    ## load ground truth\n",
    "    flist_gt = ioDT.get_image_list(\n",
    "                                            training_folder, \n",
    "                                            string_filter='_GT', \n",
    "                                            mode_filter='include'\n",
    "                                            )\n",
    "    gt_train = [ imread(f) for f in flist_gt ]\n",
    "    gt_train = [ g.astype(int) for g in gt_train ]\n",
    "\n",
    "    print('##### Training set:')\n",
    "    for i,f in enumerate(zip(flist_in,flist_gt)):\n",
    "        print(i+1,'\\t', os.path.split(f[0])[-1],'\\t', os.path.split(f[1])[-1])\n",
    "\n",
    "    ###################################################################\n",
    "    ### compute features and generate training set and weights\n",
    "\n",
    "    print('##### Generating training set...')\n",
    "    X, Y, w, scaler = train.generate_training_set( \n",
    "                                    img_train, \n",
    "                                    [g.astype(np.uint8) for g in gt_train], \n",
    "                                    sigmas = sigmas,\n",
    "                                    down_shape = downscaling,\n",
    "                                    edge_size = edge_size,\n",
    "                                    fraction = pxl_extract_fraction,\n",
    "                                    feature_mode = feature_type,\n",
    "                                    bias = pxl_extract_bias \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Training model...\n",
      "Training of Logistic Regression classifier...\n",
      "{0.0, 1.0, 2.0}\n",
      "Models trained in 0.194 seconds.\n",
      "classes_:  [0. 1. 2.]\n",
      "coef_:  [[-0.85409424 -0.84752903 -0.70476301 -3.19455644  0.12023304 -0.8631146\n",
      "   4.17909937 -4.65167898 -0.04176757 -0.70050138 -7.29429794 -0.66663825\n",
      "   0.49675211]\n",
      " [-0.31751994 -0.29268077 -0.27630206  1.77656644  0.45489563 -0.7109808\n",
      "   2.63987679  0.30368142 -1.91709535  0.9997611   5.33776778  0.50862319\n",
      "   3.28350853]\n",
      " [ 1.17161418  1.1402098   0.98106506  1.41799    -0.57512867  1.5740954\n",
      "  -6.81897616  4.34799756  1.95886292 -0.29925972  1.95653016  0.15801506\n",
      "  -3.78026064]]\n",
      "##### Model saved!\n",
      "All models saved, move to the next step.\n"
     ]
    }
   ],
   "source": [
    "### Train the model (with Multi Layer Perceptrons, please ensure you have cuDNN installed)\n",
    "for model_folder in model_folders:\n",
    "    print('##### Training model...')\n",
    "    start = time.time()\n",
    "    classifier = train.train_classifier( X, Y, w, deep = deep )\n",
    "    print('Models trained in %.3f seconds.'%(time.time()-start))\n",
    "    if not deep:\n",
    "        print('classes_: ', classifier.classes_)\n",
    "        print('coef_: ', classifier.coef_)\n",
    "    \n",
    "    ### Save the model\n",
    "    ioML.save_model( \n",
    "                model_folder,\n",
    "                classifier,\n",
    "                scaler,\n",
    "                sigmas = sigmas,\n",
    "                down_shape = downscaling,\n",
    "                edge_size = edge_size,\n",
    "                fraction = pxl_extract_fraction,\n",
    "                feature_mode = feature_type,\n",
    "                bias = pxl_extract_bias,\n",
    "                deep = deep\n",
    "                )\n",
    "    print('##### Model saved!')\n",
    "\n",
    "print('All models saved, move to the next step.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04_predict_masks.py\n",
    "Generate binary masks for image dataset using previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image subfolders found in: Y:\\Jia_Le_Lim\\morgana_example_datasets\\gastruloids\\condA\n",
      "Path exists! Proceed!\n"
     ]
    }
   ],
   "source": [
    "# Run cell if starting from 04_train_networks.py\n",
    "import os, glob\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "# parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condA')\n",
    "parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists\n",
    "\n",
    "# add folders that you want to ignore here\n",
    "exclude_folder = []\n",
    "deep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "import scipy.ndimage as ndi\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "from morgana.DatasetTools import io as ioDT\n",
    "import morgana.DatasetTools.multiprocessing.istarmap\n",
    "from morgana.MLModel import io as ioML\n",
    "from morgana.MLModel import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out all image subfolders in parent_folder\n",
    "folder_names = next(os.walk(parent_folder))[1] \n",
    "\n",
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "model_folders_name = [os.path.split(model_folder)[-1] for model_folder in model_folders]\n",
    "\n",
    "# exclude folders in exclude_folder\n",
    "exclude_folder = ['']\n",
    "\n",
    "image_folders = [g for g in folder_names if not g in model_folders_name + exclude_folder]\n",
    "image_folders = [os.path.join(parent_folder, i) for i in image_folders]\n",
    "\n",
    "model_folders = [os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','brain_organoids','adjusted_input','model_LR')]\n",
    "image_folders = [os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','brain_organoids','adjusted_input','wt2_LR')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\Jia_Le_Lim\\morgana_example_datasets\\brain_organoids\\adjusted_input\\wt2_LR\n",
      "-------------Y:\\Jia_Le_Lim\\morgana_example_datasets\\brain_organoids\\adjusted_input\\wt2_LR------------\n",
      "##### Loading classifier model and parameters...\n",
      "##### Model loaded!\n",
      "Y:\\Jia_Le_Lim\\morgana_example_datasets\\brain_organoids\\adjusted_input\\wt2_LR\\result_segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def057b724034535a225118168d34cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_folders)):\n",
    "    \n",
    "    image_folder = image_folders[i]\n",
    "    print(image_folder)\n",
    "    if len(model_folders)>1:\n",
    "        model_folder = model_folders[i]\n",
    "    else:\n",
    "        model_folder = model_folders[0]\n",
    "\n",
    "    print('-------------'+image_folder+'------------')\n",
    "#     training_folder = os.path.join(model_folder, 'trainingset')\n",
    "#     print(model_folder, training_folder)\n",
    "\n",
    "    print('##### Loading classifier model and parameters...')\n",
    "    classifier, scaler, params = ioML.load_model( model_folder, deep = deep)\n",
    "    print('##### Model loaded!')\n",
    "\n",
    "    #######################################################################\n",
    "    ### apply classifiers and save images\n",
    "\n",
    "    result_folder = os.path.join(image_folder, 'result_segmentation')\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.mkdir(result_folder)\n",
    "    print(result_folder)\n",
    "\n",
    "    flist_in = ioDT.get_image_list(image_folder)\n",
    "    flist_in.sort()        \n",
    "    N_img = len(flist_in)\n",
    "#     print(flist_in)\n",
    "\n",
    "    # multiprocess\n",
    "    N_cores = np.clip( int(0.8 * multiprocessing.cpu_count()),1,None )\n",
    "\n",
    "    # try using multiprocessing\n",
    "    pool = multiprocessing.Pool(N_cores)\n",
    "    _ = list(   tqdm(\n",
    "                            pool.istarmap(\n",
    "                                predict.predict_single_image, \n",
    "                                zip(    flist_in, \n",
    "                                        repeat(classifier),\n",
    "                                        repeat(scaler),\n",
    "                                        repeat(params) ) ), \n",
    "                                total = N_img ) )\n",
    "\n",
    "    # sequential prediction\n",
    "#     for f in tqdm(flist_in):\n",
    "#         predict.predict_single_image(f,classifier,scaler,params)\n",
    "\n",
    "    print('All images done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

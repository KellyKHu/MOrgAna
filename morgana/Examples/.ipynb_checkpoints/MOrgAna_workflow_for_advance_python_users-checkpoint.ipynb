{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOrgAna workflow for advance python users\n",
    "This workflow is intended for users with programming background to analyse multiple image folders at once. Users can also use this notebook to select and adapt modules/functions specific to their purpose. This workflow follows the order of scripts in python_example_scripts and explains the code shown in the scripts in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Masks\n",
    "This section makes use of the code from the following scripts:\n",
    "* '01_create_model_folder.py'\n",
    "* '02_create_ground_truth.py'\n",
    "* '03_train_networks.py'\n",
    "* '04_predict_masks.py'\n",
    "* '05_select_final_mask_method.py'\n",
    "\n",
    "### 01_create_model_folder.py\n",
    "The following code chooses images from the acquired dataset to form the training dataset for the generation of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condB')\n",
    "#parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select images for training dataset\n",
    "start = 0 # increase value to exclude starting images in dataset\n",
    "dN = 0 # every dNth image will be used for the training dataset; if dN = 0, random images are taken\n",
    "\n",
    "# True: create one model for all folders; False: create one model for each image subfolder\n",
    "combine_subfolders = True\n",
    "   \n",
    "# add folders that you want to ignore here\n",
    "exclude_folder = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_folder(folder, dN=30, start=0, combine=True):\n",
    "    \n",
    "    # create folders\n",
    "    if combine:\n",
    "        model_folder = os.path.join(os.path.split(folder)[0],'model_')\n",
    "    else:\n",
    "        model_folder = os.path.join(os.path.split(folder)[0], 'model_' + os.path.split(folder)[1])\n",
    "\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.mkdir(model_folder)\n",
    "        \n",
    "    trainingset_folder = os.path.join(model_folder,'trainingset')\n",
    "    if not os.path.exists(trainingset_folder):\n",
    "        os.mkdir(trainingset_folder)\n",
    "\n",
    "    # count images and extract trainingset file names\n",
    "    flist = glob.glob(os.path.join(folder,'*.tif'))\n",
    "    flist.sort()\n",
    "    if dN:\n",
    "        flist = flist[start::dN]\n",
    "    else: \n",
    "        rng = default_rng()\n",
    "        random_choice = rng.choice(len(flist), size=np.clip(len(flist)//10, 1, None), replace=False)\n",
    "        flist = [flist[i] for i in random_choice]\n",
    "\n",
    "    \n",
    "    # copy images to trainingset folder\n",
    "    for f in flist:\n",
    "        fname = os.path.split(folder)[1] + '_' + os.path.split(f)[-1]\n",
    "        newf = os.path.join(trainingset_folder,fname)\n",
    "        if not os.path.exists(newf):\n",
    "            shutil.copy(f,newf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute parent folder as absolute path\n",
    "parent_folder = os.path.abspath(parent_folder)\n",
    "    \n",
    "# find out all image subfolders in parent_folder\n",
    "folder_names = next(os.walk(parent_folder))[1] \n",
    "    \n",
    "# exclude folders in exclude_folder\n",
    "folder_names = [g for g in folder_names if not g in exclude_folder ]\n",
    "\n",
    "for folder_name in tqdm(folder_names):\n",
    "    if not folder_name in exclude_folder:\n",
    "        folder_path = os.path.join(parent_folder, folder_name)\n",
    "\n",
    "        # for the parent_folder/every image subfolder, generate model folder and the trainingset\n",
    "        initialize_model_folder(folder_path, dN=dN, start=start, combine=combine_subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02_create_ground_truth.py\n",
    "This script creates binary masks (ground truths) for images copied into the trainingset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell if starting from 02_create_ground_truth.py\n",
    "import os, glob\n",
    "from tqdm.notebook import tqdm\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morgana.GUIs.manualmask import makeManualMask\n",
    "from morgana.DatasetTools import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5.QtWidgets\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GT_mask(model_folder, app):\n",
    "    \n",
    "    ### check that model and trainingset exist\n",
    "    if not os.path.exists(model_folder):\n",
    "        print('Warning!')\n",
    "        print(model_folder,':')\n",
    "        print('Model folder not created! Skipping this subfolder.')\n",
    "        return\n",
    "        \n",
    "    trainingset_folder = os.path.join(model_folder,'trainingset')\n",
    "    if not os.path.exists(trainingset_folder):\n",
    "        print('Warning!')\n",
    "        print(model_folder,':')\n",
    "        print('Trainingset images not found! Skipping this subfolder.')\n",
    "        return\n",
    "\n",
    "    ### load trainingset images and previously generated ground truth    \n",
    "    flist_in = io.get_image_list(trainingset_folder, string_filter='_GT', mode_filter='exclude')\n",
    "    flist_in.sort()\n",
    "    flist_gt = io.get_image_list(trainingset_folder, string_filter='_GT', mode_filter='include')\n",
    "    flist_gt.sort()\n",
    "\n",
    "    ### if no trainingset images in the folder, skip this gastruloid\n",
    "    if len(flist_in) == 0:\n",
    "        print('\\n\\nWarning, no trainingset!','Selected \"'+model_folder+'\" but no trainingset *data* detected. Transfer some images in the \"trainingset\" folder.')\n",
    "        return\n",
    "    \n",
    "    ### if there are more trainingset than ground truth, promptuse to make mask\n",
    "    if len(flist_in)!=len(flist_gt):\n",
    "        print('\\n\\nWarning, trainingset incomplete!','Selected \"'+model_folder+'\" but not all masks have been created.\\nPlease provide manually annotated masks.')\n",
    "\n",
    "        for f in flist_in:\n",
    "            fn,ext = os.path.splitext(f)\n",
    "            mask_name = fn+'_GT'+ext\n",
    "\n",
    "            \n",
    "            \n",
    "            if not os.path.exists(mask_name):\n",
    "                if not PyQt5.QtWidgets.QApplication.instance():\n",
    "                    app = PyQt5.QtWidgets.QApplication(sys.argv)\n",
    "                else:\n",
    "                    app = PyQt5.QtWidgets.QApplication.instance() \n",
    "                m = makeManualMask(f,subfolder='',fn=fn+'_GT'+ext,wsize = (2000,2000))\n",
    "                m.show()\n",
    "                app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "\n",
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]\n",
    "\n",
    "app = PyQt5.QtWidgets.QApplication(sys.argv)\n",
    "\n",
    "for model_folder in tqdm(model_folders):\n",
    "    create_GT_mask(model_folder, app)\n",
    "\n",
    "app.quit()\n",
    "print('All binary masks/ground truth images found. Move to the next step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03_train_networks.py\n",
    "This trains the model for further image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell if starting from 03_train_networks.py\n",
    "import os, glob\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions'\n",
    "parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condB')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists\n",
    "\n",
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import time\n",
    "from orgseg.DatasetTools import io as ioDT\n",
    "from orgseg.MLModel import io as ioML\n",
    "from orgseg.MLModel import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define parameters for feature generation for network training\n",
    "sigmas = [1.0, 5.0, 15.0]\n",
    "downscaling = 0.25\n",
    "edge_size = 5\n",
    "pxl_extract_fraction = 0.25\n",
    "pxl_extract_bias = 0.4\n",
    "feature_type = 'daisy' # or 'ilastik'\n",
    "deep = True # True: deep learning with Multi Layer Perceptrons; False: Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute parent folder as absolute path\n",
    "model_folders = [os.path.abspath(i) for i in model_folders]\n",
    "\n",
    "for model_folder in model_folders:\n",
    "    print('-------------'+model_folder+'------------')\n",
    "\n",
    "    training_folder = os.path.join(model_folder, 'trainingset')\n",
    "\n",
    "    ### load images\n",
    "    flist_in = ioDT.get_image_list(\n",
    "                                              training_folder, \n",
    "                                              string_filter='_GT', \n",
    "                                              mode_filter='exclude'\n",
    "                                              )\n",
    "    img_train = []\n",
    "    for f in flist_in:\n",
    "        img = imread(f)\n",
    "        if len(img.shape)==2:\n",
    "            img = np.expand_dims(img,0)\n",
    "        if img.shape[-1] == np.min(img.shape):\n",
    "            img = np.moveaxis(img, -1, 0)\n",
    "        img_train.append( img[0] )\n",
    "\n",
    "    ## load ground truth\n",
    "    flist_gt = ioDT.get_image_list(\n",
    "                                            training_folder, \n",
    "                                            string_filter='_GT', \n",
    "                                            mode_filter='include'\n",
    "                                            )\n",
    "    gt_train = [ imread(f) for f in flist_gt ]\n",
    "    gt_train = [ g.astype(int) for g in gt_train ]\n",
    "\n",
    "    print('##### Training set:')\n",
    "    for i,f in enumerate(zip(flist_in,flist_gt)):\n",
    "        print(i+1,'\\t', os.path.split(f[0])[-1],'\\t', os.path.split(f[1])[-1])\n",
    "\n",
    "    ###################################################################\n",
    "    ### compute features and generate training set and weights\n",
    "\n",
    "    print('##### Generating training set...')\n",
    "    X, Y, w, scaler = train.generate_training_set( \n",
    "                                    img_train, \n",
    "                                    [g.astype(np.uint8) for g in gt_train], \n",
    "                                    sigmas = sigmas,\n",
    "                                    down_shape = downscaling,\n",
    "                                    edge_size = edge_size,\n",
    "                                    fraction = pxl_extract_fraction,\n",
    "                                    feature_mode = feature_type,\n",
    "                                    bias = pxl_extract_bias \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model (with Multi Layer Perceptrons, please ensure you have cuDNN installed)\n",
    "for model_folder in model_folders:\n",
    "    print('##### Training model...')\n",
    "    start = time.time()\n",
    "    classifier = train.train_classifier( X, Y, w, deep = deep )\n",
    "    print('Models trained in %.3f seconds.'%(time.time()-start))\n",
    "    if not deep:\n",
    "        print('classes_: ', classifier.classes_)\n",
    "        print('coef_: ', classifier.coef_)\n",
    "    \n",
    "    ### Save the model\n",
    "    ioML.save_model( \n",
    "                model_folder,\n",
    "                classifier,\n",
    "                scaler,\n",
    "                sigmas = sigmas,\n",
    "                down_shape = downscaling,\n",
    "                edge_size = edge_size,\n",
    "                fraction = pxl_extract_fraction,\n",
    "                feature_mode = feature_type,\n",
    "                bias = pxl_extract_bias,\n",
    "                deep = deep\n",
    "                )\n",
    "    print('##### Model saved!')\n",
    "\n",
    "print('All models saved, move to the next step.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04_predict_masks.py\n",
    "Generate binary masks for image dataset using previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image subfolders found in: /Users/jialelim/Desktop/example_dataset_ipynb/condA\n",
      "Path exists! Proceed!\n"
     ]
    }
   ],
   "source": [
    "# Run cell if starting from 04_train_networks.py\n",
    "import os, glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "# select folder containing all image folders to be analysed\n",
    "# parent_folder = os.path.join('test_data','2020-09-22_conditions')\n",
    "parent_folder = os.path.join('/','Users','jialelim', 'Desktop', 'example_dataset_ipynb', 'condA')\n",
    "#parent_folder = os.path.join('Y:',os.sep,'Jia_Le_Lim','morgana_example_datasets','gastruloids','condA')\n",
    "\n",
    "print('Image subfolders found in: ' + parent_folder)\n",
    "if os.path.exists(parent_folder):\n",
    "    print('Path exists! Proceed!')# check if the path exists\n",
    "\n",
    "# add folders that you want to ignore here\n",
    "exclude_folder = []\n",
    "deep = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "import scipy.ndimage as ndi\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "from orgseg.DatasetTools import io as ioDT\n",
    "import orgseg.DatasetTools.multiprocessing.istarmap\n",
    "from orgseg.MLModel import io as ioML\n",
    "from orgseg.MLModel import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out all image subfolders in parent_folder\n",
    "folder_names = next(os.walk(parent_folder))[1] \n",
    "\n",
    "model_folders = glob.glob(os.path.join(parent_folder,'model_*'))\n",
    "model_folders_name = [os.path.split(model_folder)[-1] for model_folder in model_folders]\n",
    "\n",
    "# exclude folders in exclude_folder\n",
    "exclude_folder = ['']\n",
    "\n",
    "image_folders = [g for g in folder_names if not g in model_folders_name + exclude_folder]\n",
    "image_folders = [os.path.join(parent_folder, i) for i in image_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(f_in, classifier, scaler, params):\n",
    "\n",
    "    parent, filename = os.path.split(f_in)\n",
    "    filename, file_extension = os.path.splitext(filename)\n",
    "    new_name_classifier = os.path.join(\n",
    "                    parent,\n",
    "                    'result_segmentation',\n",
    "                    filename+'_classifier'+file_extension\n",
    "                    )\n",
    "    new_name_watershed = os.path.join(\n",
    "                    parent,\n",
    "                    'result_segmentation',\n",
    "                    filename+'_watershed'+file_extension\n",
    "                    )\n",
    "\n",
    "#    print('#'*20+'\\nLoading',f_in,'...')\n",
    "    img = imread(f_in)\n",
    "    if len(img.shape)==2:\n",
    "        img = np.expand_dims(img,0)\n",
    "    if img.shape[-1] == np.min(img.shape):\n",
    "        img = np.moveaxis(img, -1, 0)\n",
    "    img = img[0]\n",
    "\n",
    "    if not os.path.exists(new_name_classifier):\n",
    "        # print('Predicting image...')\n",
    "\n",
    "        pred, prob = predict.predict_image( \n",
    "                            img,\n",
    "                            classifier,\n",
    "                            scaler,\n",
    "                            sigmas = params['sigmas'],\n",
    "                            new_shape_scale = params['down_shape'],\n",
    "                            feature_mode = params['feature_mode']\n",
    "                            )\n",
    "    \n",
    "        # remove objects at the border\n",
    "        negative = ndi.binary_fill_holes(pred==0)\n",
    "        mask_pred = (pred==1)*negative\n",
    "        edge_prob = ((2**16-1)*prob[2]).astype(np.uint16)\n",
    "        mask_pred = mask_pred.astype(np.uint8)\n",
    "    \n",
    "        # save mask\n",
    "        imsave(new_name_classifier, pred)\n",
    "\n",
    "    if not os.path.exists(new_name_watershed):\n",
    "        # perform watershed\n",
    "        mask_final = predict.make_watershed(\n",
    "                            mask_pred,\n",
    "                            edge_prob,\n",
    "                            new_shape_scale = params['down_shape'] \n",
    "                            )\n",
    "    \n",
    "        # save final mask\n",
    "        imsave(new_name_watershed, mask_final)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h\n",
      "-------------/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h------------\n",
      "/Users/jialelim/Desktop/example_dataset_ipynb/condA/model_condA_72h /Users/jialelim/Desktop/example_dataset_ipynb/condA/model_condA_72h/trainingset\n",
      "##### Loading classifier model and parameters...\n",
      "##### Model loaded!\n",
      "/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/result_segmentation\n",
      "['/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/03D.tif', '/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/03E.tif', '/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/03F.tif', '/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/03G.tif', '/Users/jialelim/Desktop/example_dataset_ipynb/condA/condA_120h/03H.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Loader._recreate_base_user_object.<locals>._UserObject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a712e0ec8a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# try using multiprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     _ = list(   tqdm.tqdm(\n\u001b[0m\u001b[1;32m     37\u001b[0m                             pool.istarmap(\n\u001b[1;32m     38\u001b[0m                                 \u001b[0mpredict_single_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/orgseg-0.1.0-py3.8.egg/orgseg/DatasetTools/multiprocessing/istarmap.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         ))\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'Loader._recreate_base_user_object.<locals>._UserObject'"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_folders)):\n",
    "    \n",
    "    image_folder = image_folders[i]\n",
    "    print(image_folder)\n",
    "    if len(model_folders)>1:\n",
    "        model_folder = model_folders[i]\n",
    "    else:\n",
    "        model_folder = model_folders\n",
    "\n",
    "    print('-------------'+image_folder+'------------')\n",
    "    training_folder = os.path.join(model_folder, 'trainingset')\n",
    "    print(model_folder, training_folder)\n",
    "\n",
    "    print('##### Loading classifier model and parameters...')\n",
    "    classifier, scaler, params = ioML.load_model( model_folder, deep = deep)\n",
    "    print('##### Model loaded!')\n",
    "\n",
    "    #######################################################################\n",
    "    ### apply classifiers and save images\n",
    "\n",
    "    result_folder = os.path.join(image_folder, 'result_segmentation')\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.mkdir(result_folder)\n",
    "    print(result_folder)\n",
    "\n",
    "    flist_in = ioDT.get_image_list(image_folder)\n",
    "    flist_in.sort()        \n",
    "    N_img = len(flist_in)\n",
    "    print(flist_in)\n",
    "\n",
    "    # multiprocess\n",
    "    N_cores = np.clip( int(0.8 * multiprocessing.cpu_count()),1,None )\n",
    "\n",
    "    # try using multiprocessing\n",
    "    pool = multiprocessing.Pool(N_cores)\n",
    "    _ = list(   tqdm.tqdm(\n",
    "                            pool.istarmap(\n",
    "                                predict_single_image, \n",
    "                                zip(    flist_in, \n",
    "                                        repeat(classifier),\n",
    "                                        repeat(scaler),\n",
    "                                        repeat(params) ) ), \n",
    "                                total = N_img ) )\n",
    "\n",
    "    print('All images done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
